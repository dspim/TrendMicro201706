---
title: "Advanced Data Analysis Training"
author: "Wush Wu"
date: "June 01, 2017"
output:
  ioslides_presentation:
    css: 
      - css/dsp.css
      -  css/2017-06-07.css
    self_contained: no
    widescreen: yes
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set_notes <- function(s) {
  sprintf('<div class="notes">%s</div>', s)
}
set_image <- function(name) {
  sprintf('<img src="img/%s" style="height:400px"></img>', name)
}
```

# 資料科學的Hello World

## Dashboard的製作就是資料科學團隊的Hello World

<center>
<img src='img/Lf5Q79U.png' style='height: 400px'></img>
</center>

## 檢驗資料的品質

<center>
<img src='img/AAEAAQAAAAAAAAMFAAAAJDAyYTM0YTMzLWQ3YjMtNDYxMy1iNTI5LWZhN2M1ZGRiNDNmYg.jpg', style='height: 400px'></img>
</center>

<div class="notes">
Source: https://www.linkedin.com/pulse/supply-chain-planning-garbage-out-cheryl-wiebe
</div>

## 檢驗科學家們對資料的理解

<center>
<img src='img/data-science-for-smart-manufacturing-12-1024.jpg', style='height:400px'></img>
</center>

<div class="notes">Source: https://www.slideshare.net/carlotorniai/data-science-for-smart-manufacturing</div>

## 每導入一個資料源，就應該要製作對應的Dashboard

### 上游污染、下游受害

<center>
`r set_image("article-2646549-1E6B5BE200000578-780_964x705.jpg")`
</center>

`r set_notes("http://www.dailymail.co.uk/indiahome/indianews/article-2646549/Ganga-clean-Himalayan-task-The-challenges-facing-Modis-mission-improve-Indias-polluted-river.html")`

## Dashboard能為資料科學團隊建立初步的信譽

<center>
<img src='img/22-768x768.jpg', style='height:400px'></img>
</center>

`r set_notes("Source: http://community.uservoice.com/blog/you-cant-have-trust-without-transparency/")`

# 資料分析的目的是價值

## 資料部門在企業中是成本單位

<center>
`r set_image("cost-accounting-40.jpg")`
</center>

`r set_notes("http://www.referenceforbusiness.com/encyclopedia/Con-Cos/Cost-Accounting.html")`

## 老闆對資料團隊的期待...?

<center>
`r set_image("toug-big-data-challenge-and-impact-2-638.jpg")`
</center>

`r set_notes("https://www.slideshare.net/Toronto-Oracle-Users-Group/toug-big-data-challenge-and-impact-v1")`

## 有時老闆已經知道團隊的任務 {.smaller .columns-2 .centered}
<img src='img/coins_on_chart.jpeg' style='height: 400px'></img>
<h3>金融投資、避險</h3>
取自 <https://goo.gl/4USt8w>

<img src='img/Humor_recommender.jpeg' style='height: 400px'></img>
<h3>廣告推薦引擎</h3>
取自 <https://goo.gl/FAe9V9>

## 有時資料科學家要自己發想問題{.smaller .columns-2 .centered}
<img src='img/google-data-center.jpeg' 
style='padding-left: 30px'></img>
<h3>Google用Machine Learning省電</h3>
取自 <https://goo.gl/vOc0h4>

<img src='img/ups-trucks-NOLEFT0217-400.jpeg' 
style='padding-right: 30px'></img>
<h3>貨運公司UPS發現不左轉比較省油</h3>
取自 <https://goo.gl/hwWvzZ>

## 但是老闆不願意只看到......{.smaller .centered}
<img src='img/academic.jpeg' style='height: 400px'></img>
<h3>方法的「創新」不重要，重要的是對公司帶來的影響</h3>
取自 <https://goo.gl/1eiyeM>

## 問題：對一個資料科學團隊，怎麼產生價值？

# 資料整合是新價值的捷徑

## 數據分析是個悠久的知識產業

- 玉山銀行的CRM部門已經十年......
- 工廠用資料做品管提升已經數十年......

## 單一資料可能已經被分析得透徹...

- 分析獲得的知識，要「新」才有意義

## 大數據時的不同

<center>
`r set_image("big-data-ppt-6-638.jpg")`
</center>

`r set_notes("https://www.slideshare.net/nasrinhussain1/big-data-ppt-31616290")`

## {.Selection_096}

## 資料整合變成產生價值的捷徑{.smaller .centered}
<img src='img/hacker.jpeg' style='height: 350px'></img>
<h3>資策會資安所把不同廠商的資安紀錄整合</h3>
<h3>==> 可以觀察與追蹤跨區駭客的足跡</h3>
取自 <https://goo.gl/5L6DWH>

## 資料整合變成產生價值的捷徑{.smaller .centered}
<img src='img/Airport.jpeg' style='width: 960px'></img>
<h3>風速資料與機場起降資料整合 ==> 發現兩者的關係</h3>
取自 <https://goo.gl/do4Ew2>

## 資料整合變成產生價值的捷徑{.smaller .centered}
<img src='img/Global-Real-Estate-Bubble.jpeg' style='height: 400px'></img>
<h3>房貸餘額與GDP的整合 ==> 房地產泡沫化指數</h3>
取自 <https://goo.gl/tH0RWw>

# 資料整合的方式

## SQL 上的資料整合

請參考 https://en.wikipedia.org/wiki/Join_(SQL) 上的說明幫我做個1~2頁的介紹，如果不行就留白我之後自己補上

## 常見時間資料整合的問題：{.smaller .centered}
<img src='img/car-dashboard-indicators.jpeg' style='height: 400px'></img>
<h3>相同欄位對應的意義不一定一樣</h3>
取自 <https://goo.gl/LX06rE>

## 解決辦法

找出合理的比對時間點

## 常見的空間資料整合問題

# 實務上的注意事項

## 對資料的操作可以CREATE、READ但不要UPDATE、DELETE

Immutable 對資料品質非常重要

## Immutable Data

處理資料時犯錯後，只能回溯沒有被Update/Delete的部分

## 假刪除

添增欄位：IsDelete

## 用版本取代Update/Delete

添增欄位：Version、mtime等等

## Hadoop時代......

每次Transform告一段落後就寫入snapshot

每次清理後資料都會變小：PB-->TB-->GB-->MB...
